{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to <code>OP Engine</code>","text":"<p>The next generation vectorized compartmental model engine for <code>flepimop2</code>.</p>"},{"location":"api-reference/core_solver/","title":"Core Solver","text":""},{"location":"api-reference/core_solver/#op_engine.core_solver","title":"<code>core_solver</code>","text":"<p>Core semi-implicit solver for time-evolving models (ODE + IMEX multiphysics).</p> <p>This solver advances a :class:<code>op_engine.model_core.ModelCore</code> instance over its configured time grid. In the updated semantics, ModelCore.time_grid is treated as output times: the times at which the user wants a stored solution state.</p> <p>Between consecutive output times, the solver may take either: - exactly one step of size dt = t_{i+1} - t_i (adaptive=False), or - multiple internal adaptive substeps that land exactly on t_{i+1} (adaptive=True).</p> <p>Supported methods (keyword <code>method=</code>):     - \"euler\":        Explicit Euler (order 1), adaptive via step-doubling.     - \"heun\":         Explicit Heun / RK2 (order 2), embedded Euler estimator.     - \"imex-euler\":   IMEX Euler: explicit Euler on F(t,y), implicit Euler on A.                       Adaptive via step-doubling (IMEX step-doubling).     - \"imex-heun-tr\": IMEX Heun-Trapezoidal: Heun on F, trapezoidal/CN on A.                       Adaptive via embedded low/high (Euler vs Heun) mapped by the                       same implicit operator solve.     - \"imex-trbdf2\":  IMEX TR-BDF2 (order 2), adaptive via step-doubling.</p> IMEX structure <p>We assume a split system:     y' = A(t,y) y + F(t,y) where F is provided by rhs_func(t, y), and A is represented by linear operators applied along a single tensor axis. Operators may be:     - None (ODE-only / explicit-only behavior), or     - provided as tuples (predictor?, L, R), or     - provided as factories depending on dt, stage-scale, and context.</p> Operator application <p>Operators act along a configured axis (default \"state\"). All other axes are batched. The solve form is:     L @ y_next = R @ x optionally with a preprocessing predictor:     x_tilde = predictor @ x</p> Non-uniform dt <ul> <li>Explicit methods naturally support non-uniform dt.</li> <li>Implicit/IMEX methods require operator factories whenever dt varies across   steps (non-uniform output grid or adaptive stepping), because L/R depend on dt.</li> </ul> Performance hygiene <ul> <li>All major scratch arrays are preallocated.</li> <li>Inner loops use in-place NumPy ops and np.copyto.</li> <li>Implicit solves are delegated to matrix_ops.implicit_solve (cached factorization).</li> </ul>"},{"location":"api-reference/core_solver/#op_engine.core_solver.AdaptiveAdvanceParams","title":"<code>AdaptiveAdvanceParams(plan, t0, t1, y0, adaptive_cfg, dt_ctrl)</code>  <code>dataclass</code>","text":"<p>Bundle of parameters for adaptive advancement to an output time.</p> <p>Attributes:</p> Name Type Description <code>plan</code> <code>RunPlan</code> <p>Resolved run plan.</p> <code>t0</code> <code>float</code> <p>Start time.</p> <code>t1</code> <code>float</code> <p>End/output time.</p> <code>y0</code> <code>NDArray[floating]</code> <p>Initial state at t0.</p> <code>adaptive_cfg</code> <code>AdaptiveConfig</code> <p>Adaptive stepping configuration.</p> <code>dt_ctrl</code> <code>DtControllerConfig</code> <p>dt controller configuration.</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.AdaptiveConfig","title":"<code>AdaptiveConfig(rtol=1e-06, atol=1e-09, dt_init=None, max_reject=25, max_steps=1000000)</code>  <code>dataclass</code>","text":"<p>Configuration for adaptive stepping.</p> <p>Attributes:</p> Name Type Description <code>rtol</code> <code>float</code> <p>Relative tolerance.</p> <code>atol</code> <code>float | NDArray[floating]</code> <p>Absolute tolerance (scalar or array-like).</p> <code>dt_init</code> <code>float | None</code> <p>Optional initial dt guess; if None, use output dt.</p> <code>max_reject</code> <code>int</code> <p>Maximum number of rejected attempts per accepted step.</p> <code>max_steps</code> <code>int</code> <p>Maximum number of internal substeps per output interval.</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.CoreSolver","title":"<code>CoreSolver(core, operators=None, *, operator_axis='state')</code>","text":"<p>Semi-implicit solver operating on a ModelCore time/state grid.</p> <p>Initialize CoreSolver.</p> <p>Parameters:</p> Name Type Description Default <code>core</code> <code>ModelCore</code> <p>ModelCore instance to solve.</p> required <code>operators</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>Default operator spec (tuple or factory) for implicit stages.</p> <code>None</code> <code>operator_axis</code> <code>str | int</code> <p>Axis along which operators act (name or index).</p> <code>'state'</code> Source code in <code>src/op_engine/core_solver.py</code> <pre><code>def __init__(\n    self,\n    core: ModelCore,\n    operators: CoreOperators | StageOperatorFactory | None = None,\n    *,\n    operator_axis: str | int = \"state\",\n) -&gt; None:\n    \"\"\"Initialize CoreSolver.\n\n    Args:\n        core: ModelCore instance to solve.\n        operators: Default operator spec (tuple or factory) for implicit stages.\n        operator_axis: Axis along which operators act (name or index).\n    \"\"\"\n    self.core = core\n    self.dtype = core.dtype\n    self.state_shape = core.state_shape\n    self.state_ndim = len(self.state_shape)\n\n    # Operator axis resolution\n    self._op_axis = operator_axis\n    self._op_axis_idx: int | None = None\n    self._op_axis_len: int | None = None\n\n    # Default operator spec (tuple or factory or None)\n    self._default_operator_spec: CoreOperators | StageOperatorFactory | None = (\n        operators\n    )\n\n    # Preallocate buffers (full tensor shape)\n    self._rhs_buffer: NDArray[np.floating] = np.zeros(\n        self.state_shape,\n        dtype=self.dtype,\n    )\n    self._next_state_buffer: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n\n    # Shared stepping buffers\n    self._f_n: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._f_pred: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._state_pred: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n\n    # Adaptive buffers\n    self._y_full: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._y_half: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._y_two_half: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._y_low: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._err: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._scale: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._ratio: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n\n    # Working state buffers (avoid allocating per substep)\n    self._y_curr: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._y_try: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n\n    # TR-BDF2 additional buffers\n    self._y_stage1: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._f_stage1: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n    self._f_extrap: NDArray[np.floating] = np.zeros_like(self._rhs_buffer)\n\n    # Validate operator sizes if default spec is a static tuple\n    if operators is not None and not callable(operators):\n        _predictor, left_op, right_op = self._normalize_ops_tuple(operators)\n        if left_op is not None and right_op is not None:\n            self._resolve_operator_axis()\n            self._validate_operator_sizes(left_op, right_op)\n</code></pre>"},{"location":"api-reference/core_solver/#op_engine.core_solver.CoreSolver.run","title":"<code>run(rhs_func, *, config=None)</code>","text":"<p>Advance the ModelCore state through its time grid.</p> <p>Parameters:</p> Name Type Description Default <code>rhs_func</code> <code>RHSFunction</code> <p>Function computing the explicit RHS F(t, y).</p> required <code>config</code> <code>RunConfig | None</code> <p>Optional run configuration. If None, defaults are used.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If invalid parameters are provided.</p> Source code in <code>src/op_engine/core_solver.py</code> <pre><code>def run(self, rhs_func: RHSFunction, *, config: RunConfig | None = None) -&gt; None:\n    \"\"\"Advance the ModelCore state through its time grid.\n\n    Args:\n        rhs_func: Function computing the explicit RHS F(t, y).\n        config: Optional run configuration. If None, defaults are used.\n\n    Raises:\n        ValueError: If invalid parameters are provided.\n    \"\"\"\n    cfg = config or RunConfig()\n    plan = self._resolve_run_plan(cfg)\n\n    time_grid = np.asarray(self.core.time_grid, dtype=float)\n    n_steps = int(self.core.n_timesteps)\n\n    for idx in range(n_steps - 1):\n        t0 = float(time_grid[idx])\n        t1 = float(time_grid[idx + 1])\n        if t1 &lt;= t0:\n            raise ValueError(_TIME_GRID_INCREASING_ERROR_MSG)\n        dt_out = t1 - t0\n\n        np.copyto(self._y_curr, self.core.get_current_state())\n\n        if not cfg.adaptive:\n            y_next = self._advance_nonadaptive_to_time(\n                rhs_func,\n                plan=plan,\n                t0=t0,\n                dt_out=dt_out,\n                y0=self._y_curr,\n            )\n            self.core.advance_timestep(y_next)\n            continue\n\n        y_end = self._advance_adaptive_to_time(\n            rhs_func,\n            AdaptiveAdvanceParams(\n                plan=plan,\n                t0=t0,\n                t1=t1,\n                y0=self._y_curr,\n                adaptive_cfg=cfg.adaptive_cfg,\n                dt_ctrl=cfg.dt_controller,\n            ),\n        )\n        self.core.advance_timestep(y_end)\n</code></pre>"},{"location":"api-reference/core_solver/#op_engine.core_solver.DtControllerConfig","title":"<code>DtControllerConfig(dt_min=0.0, dt_max=float('inf'), safety=0.9, fac_min=0.2, fac_max=5.0)</code>  <code>dataclass</code>","text":"<p>Configuration for adaptive timestep control.</p> <p>Attributes:</p> Name Type Description <code>dt_min</code> <code>float</code> <p>Minimum allowed dt.</p> <code>dt_max</code> <code>float</code> <p>Maximum allowed dt.</p> <code>safety</code> <code>float</code> <p>Safety factor applied to dt updates.</p> <code>fac_min</code> <code>float</code> <p>Minimum multiplicative change factor.</p> <code>fac_max</code> <code>float</code> <p>Maximum multiplicative change factor.</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.ImexEulerOnceParams","title":"<code>ImexEulerOnceParams(t, y, dt, op_spec, out)</code>  <code>dataclass</code>","text":"<p>Bundle of parameters for one IMEX Euler step (non-doubling).</p> <p>Attributes:</p> Name Type Description <code>t</code> <code>float</code> <p>Current time.</p> <code>y</code> <code>NDArray[floating]</code> <p>Current state.</p> <code>dt</code> <code>float</code> <p>Step size.</p> <code>op_spec</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>Operator spec for implicit stage.</p> <code>out</code> <code>NDArray[floating]</code> <p>Output state array (written in-place).</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.ImplicitStageParams","title":"<code>ImplicitStageParams(spec, dt, scale, t_stage, y_stage, stage, x, out)</code>  <code>dataclass</code>","text":"<p>Bundle of parameters for one implicit operator application.</p> <p>Attributes:</p> Name Type Description <code>spec</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>Operator spec (tuple or factory) or None for identity.</p> <code>dt</code> <code>float</code> <p>Full-step dt for operator factory context.</p> <code>scale</code> <code>float</code> <p>Stage scaling factor for dt-dependent operators.</p> <code>t_stage</code> <code>float</code> <p>Stage time.</p> <code>y_stage</code> <code>NDArray[floating]</code> <p>Stage state proxy for operator factories.</p> <code>stage</code> <code>str</code> <p>Stage label (e.g., \"be\", \"tr\", \"bdf2\").</p> <code>x</code> <code>NDArray[floating]</code> <p>Input array to map.</p> <code>out</code> <code>NDArray[floating]</code> <p>Output array (written in-place).</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.OperatorLike","title":"<code>OperatorLike</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Minimal operator interface required by CoreSolver.</p> <p>Implementations are expected to behave like 2D linear operators suitable for implicit_solve(L, R, rhs2d). Only shape is required for validation.</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.OperatorLike.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Return the operator shape.</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.OperatorSpecs","title":"<code>OperatorSpecs(default=None, tr=None, bdf2=None)</code>  <code>dataclass</code>","text":"<p>Operator specifications for implicit/IMEX methods.</p> <p>Attributes:</p> Name Type Description <code>default</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>Default operator spec (tuple or factory) used by IMEX Euler/Heun-TR and as a fallback for TR/BDF2 stages.</p> <code>tr</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>Operator spec for trapezoidal stage of TR-BDF2 (optional).</p> <code>bdf2</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>Operator spec for BDF2 stage of TR-BDF2 (optional).</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.PredictorLike","title":"<code>PredictorLike</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Minimal predictor interface required by CoreSolver.</p> The predictor is an optional preprocessing operator applied as <p>rhs2d = predictor @ rhs2d</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.PredictorLike.__matmul__","title":"<code>__matmul__(other)</code>","text":"<p>Apply the predictor to a 2D array.</p> Source code in <code>src/op_engine/core_solver.py</code> <pre><code>def __matmul__(self, other: NDArray[np.floating]) -&gt; NDArray[np.floating]:\n    \"\"\"Apply the predictor to a 2D array.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/core_solver/#op_engine.core_solver.RunConfig","title":"<code>RunConfig(method='heun', adaptive=False, strict=True, dt_controller=DtControllerConfig(), adaptive_cfg=AdaptiveConfig(), operators=OperatorSpecs(), gamma=None)</code>  <code>dataclass</code>","text":"<p>Configuration for CoreSolver.run.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>Method name.</p> <code>adaptive</code> <code>bool</code> <p>Whether to use adaptive substepping between output times.</p> <code>strict</code> <code>bool</code> <p>If True, invalid configurations raise; otherwise warnings and method downshifts may occur.</p> <code>dt_controller</code> <code>DtControllerConfig</code> <p>Parameters for dt controller when adaptive=True.</p> <code>adaptive_cfg</code> <code>AdaptiveConfig</code> <p>Parameters controlling error tolerances and limits.</p> <code>operators</code> <code>OperatorSpecs</code> <p>Operator specifications for implicit/IMEX methods.</p> <code>gamma</code> <code>float | None</code> <p>Optional TR-BDF2 gamma (if None, uses default).</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.RunPlan","title":"<code>RunPlan(method, gamma, op_default, op_tr, op_bdf2)</code>  <code>dataclass</code>","text":"<p>Resolved execution plan derived from RunConfig.</p> <p>This is the internal, validated form used by the stepping loops.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>MethodName</code> <p>Final method after any strict=False downshifts.</p> <code>gamma</code> <code>float | None</code> <p>TR-BDF2 gamma, or None for non-TR-BDF2 methods.</p> <code>op_default</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>Operator spec for IMEX Euler/Heun-TR.</p> <code>op_tr</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>TR-stage operator spec for TR-BDF2.</p> <code>op_bdf2</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>BDF2-stage operator spec for TR-BDF2.</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.StepIO","title":"<code>StepIO(t, dt, y, out, err_out=None)</code>  <code>dataclass</code>","text":"<p>Bundle of per-step state for stepping kernels.</p> <p>Attributes:</p> Name Type Description <code>t</code> <code>float</code> <p>Current time.</p> <code>dt</code> <code>float</code> <p>Step size.</p> <code>y</code> <code>NDArray[floating]</code> <p>Current state array (input).</p> <code>out</code> <code>NDArray[floating]</code> <p>Output state array (written in-place).</p> <code>err_out</code> <code>NDArray[floating] | None</code> <p>Error estimate array (written in-place) for adaptive methods.</p>"},{"location":"api-reference/core_solver/#op_engine.core_solver.Trbdf2OnceParams","title":"<code>Trbdf2OnceParams(t, y, dt, operators_tr, operators_bdf2, gamma, out)</code>  <code>dataclass</code>","text":"<p>Bundle of parameters for one TR-BDF2 step (non-doubling).</p> <p>Attributes:</p> Name Type Description <code>t</code> <code>float</code> <p>Current time.</p> <code>y</code> <code>NDArray[floating]</code> <p>Current state.</p> <code>dt</code> <code>float</code> <p>Step size.</p> <code>operators_tr</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>TR stage operator spec.</p> <code>operators_bdf2</code> <code>CoreOperators | StageOperatorFactory | None</code> <p>BDF2 stage operator spec.</p> <code>gamma</code> <code>float</code> <p>TR-BDF2 gamma.</p> <code>out</code> <code>NDArray[floating]</code> <p>Output state array (written in-place).</p>"},{"location":"api-reference/matrix_ops/","title":"Matrix Ops","text":""},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops","title":"<code>matrix_ops</code>","text":"<p>Matrix operations and linear solvers for multiphysics modeling.</p> <p>This module provides small, performance-oriented numerical utilities used by multiphysics engines:</p> <ul> <li>Construction of common 1D linear operators (e.g., Laplacian, Crank-Nicolson).</li> <li>Cached implicit solves for repeated linear systems with fixed operators.</li> <li>High-throughput aggregation utilities for large numbers of subpopulations.</li> <li>Optional Kronecker composition utilities for separable multi-axis operators.</li> </ul> Design notes <ul> <li>CPU-first: dense paths rely on NumPy/SciPy BLAS/LAPACK; sparse paths rely   on SciPy sparse factorizations.</li> <li>Backend-friendly surface: public APIs operate on plain ndarrays or CSR   matrices and avoid leaking SciPy-specific solver objects.</li> <li>Cache semantics: implicit solver caching is keyed by (id(left_op),   id(right_op)). For caching to be effective, operator objects must be   constructed once and reused.</li> </ul> <p>Stage operator factories (IMEX/TR-BDF2 support):     TR-BDF2 and similar IMEX methods can require stage-specific implicit     operators that depend on:         - dt (time step)         - scale (method stage scalar)         - t (stage time)         - y (stage state)         - stage (a label, e.g. \"tr\" or \"bdf2\")</p> <pre><code>This module supports dynamic base operators via a builder:\n    base_builder(t, y, stage) -&gt; Operator\n\nThen the stage-operator factory produces (L, R) to solve:\n    L @ y_next = R @ y_in\n\nwhere (L, R) follow schemes like implicit Euler or trapezoidal.\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.DiffusionConfig","title":"<code>DiffusionConfig(coeff, dtype=np.float64, bc='neumann')</code>  <code>dataclass</code>","text":"<p>Configuration for diffusion-like linear operators.</p> <p>Attributes:</p> Name Type Description <code>coeff</code> <code>float</code> <p>Physical diffusion coefficient D (units length^2 / time).</p> <code>dtype</code> <code>DTypeLike</code> <p>Floating dtype (e.g. np.float64).</p> <code>bc</code> <code>str</code> <p>Boundary condition; either \"neumann\" or \"absorbing\".</p>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.GridGeometry","title":"<code>GridGeometry(n, dx)</code>  <code>dataclass</code>","text":"<p>Geometry of a 1D spatial grid.</p> <p>Attributes:</p> Name Type Description <code>n</code> <code>int</code> <p>Number of grid points.</p> <code>dx</code> <code>float</code> <p>Grid spacing.</p>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.StageOperatorContext","title":"<code>StageOperatorContext(t, y, stage=None, extra=None)</code>  <code>dataclass</code>","text":"<p>Context passed to time/state-dependent operator builders.</p> <p>Attributes:</p> Name Type Description <code>t</code> <code>float</code> <p>Stage time.</p> <code>y</code> <code>NDArray[floating]</code> <p>Stage state as a 1D float array (flattened along solver operator axis).</p> <code>stage</code> <code>StageName</code> <p>Optional stage label (e.g. \"tr\", \"bdf2\").</p> <code>extra</code> <code>Any | None</code> <p>Optional extra payload for future use (kept generic).</p>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.build_crank_nicolson_operator","title":"<code>build_crank_nicolson_operator(geom, cfg, dt)</code>","text":"<p>Build Crank-Nicolson operators with dense/sparse autodispatch.</p> <p>Parameters:</p> Name Type Description Default <code>geom</code> <code>GridGeometry</code> <p>Grid geometry.</p> required <code>cfg</code> <code>DiffusionConfig</code> <p>Diffusion configuration.</p> required <code>dt</code> <code>float</code> <p>Time step.</p> required <p>Returns:</p> Type Description <code>tuple[Operator, Operator]</code> <p>Tuple of (L, R) operators for Crank-Nicolson scheme.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def build_crank_nicolson_operator(\n    geom: GridGeometry,\n    cfg: DiffusionConfig,\n    dt: float,\n) -&gt; tuple[Operator, Operator]:\n    \"\"\"\n    Build Crank-Nicolson operators with dense/sparse autodispatch.\n\n    Args:\n        geom: Grid geometry.\n        cfg: Diffusion configuration.\n        dt: Time step.\n\n    Returns:\n        Tuple of (L, R) operators for Crank-Nicolson scheme.\n    \"\"\"\n    if geom.n &lt; _DISPATCH_THRESHOLD:\n        return _build_crank_nicolson_dense(geom, cfg, dt)\n    return _build_crank_nicolson_sparse(geom, cfg, dt)\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.build_identity_operator","title":"<code>build_identity_operator(n, *, dtype=np.float64, prefer_sparse=None)</code>","text":"<p>Build an identity operator with dense/sparse autodispatch.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Size of the identity operator (n x n).</p> required <code>dtype</code> <code>DTypeLike</code> <p>Floating dtype (e.g. np.float64).</p> <code>float64</code> <code>prefer_sparse</code> <code>bool | None</code> <p>If True, always return a sparse operator; if False, always return a dense operator; if None, autodispatch based on n.</p> <code>None</code> <p>Returns:</p> Type Description <code>Operator</code> <p>Identity operator of shape (n, n) as either a dense ndarray or CSR matrix.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def build_identity_operator(\n    n: int,\n    *,\n    dtype: DTypeLike = np.float64,\n    prefer_sparse: bool | None = None,\n) -&gt; Operator:\n    \"\"\"\n    Build an identity operator with dense/sparse autodispatch.\n\n    Args:\n        n: Size of the identity operator (n x n).\n        dtype: Floating dtype (e.g. np.float64).\n        prefer_sparse: If True, always return a sparse operator; if False,\n            always return a dense operator; if None, autodispatch based on n.\n\n    Returns:\n        Identity operator of shape (n, n) as either a dense ndarray or CSR matrix.\n    \"\"\"\n    dtype_obj = np.dtype(dtype)\n\n    if prefer_sparse is True:\n        return identity(n, format=\"csr\", dtype=dtype_obj)\n\n    if prefer_sparse is False:\n        return cast(\"DenseOperator\", np.eye(n, dtype=dtype_obj))\n\n    # Autodispatch\n    if n &gt;= _DISPATCH_THRESHOLD:\n        return identity(n, format=\"csr\", dtype=dtype_obj)\n\n    return cast(\"DenseOperator\", np.eye(n, dtype=dtype_obj))\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.build_implicit_euler_operators","title":"<code>build_implicit_euler_operators(base_op, dt_scale)</code>","text":"<p>Build implicit Euler operators for a time-scaled linear operator.</p> <p>Parameters:</p> Name Type Description Default <code>base_op</code> <code>Operator</code> <p>Base linear operator A.</p> required <code>dt_scale</code> <code>float</code> <p>Time-step scaling factor (dt * scale).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If dt_scale is not finite.</p> <p>Returns:</p> Type Description <code>tuple[Operator, Operator]</code> <p>Tuple of (L, R) operators for implicit Euler scheme.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def build_implicit_euler_operators(\n    base_op: Operator,\n    dt_scale: float,\n) -&gt; tuple[Operator, Operator]:\n    \"\"\"Build implicit Euler operators for a time-scaled linear operator.\n\n    Args:\n        base_op: Base linear operator A.\n        dt_scale: Time-step scaling factor (dt * scale).\n\n    Raises:\n        ValueError: If dt_scale is not finite.\n\n    Returns:\n        Tuple of (L, R) operators for implicit Euler scheme.\n    \"\"\"\n    if not np.isfinite(dt_scale):\n        raise ValueError(_OPERATOR_SCALE_ERROR.format(scale=dt_scale))\n\n    n = base_op.shape[0]\n\n    if issparse(base_op):\n        base_csr = base_op.tocsr()\n        identity_csr = identity(n, format=\"csr\", dtype=base_csr.dtype)\n        left_csr = (identity_csr - (dt_scale * base_csr)).tocsr()\n        right_csr = identity_csr.tocsr()\n        return left_csr, right_csr\n\n    base_arr = np.asarray(base_op)\n    identity_arr = np.eye(n, dtype=base_arr.dtype)\n    left_arr = identity_arr - (dt_scale * base_arr)\n    right_arr = identity_arr\n    return cast(\"DenseOperator\", left_arr), cast(\"DenseOperator\", right_arr)\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.build_laplacian_tridiag","title":"<code>build_laplacian_tridiag(n, dx, coeff, dtype=np.float64, bc='neumann')</code>","text":"<p>Build a Laplacian tridiagonal matrix for a given boundary condition.</p> <p>The resulting operator corresponds to <code>coeff * \u0394_h</code>, where <code>\u0394_h</code> is the standard second-order central-difference Laplacian in 1D. No time-step scaling is applied here; <code>coeff</code> is interpreted as the physical diffusion coefficient <code>D</code> or a generic spatial scaling.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of grid points.</p> required <code>dx</code> <code>float</code> <p>Grid spacing.</p> required <code>coeff</code> <code>float</code> <p>Physical diffusion coefficient D (units length^2 / time).</p> required <code>dtype</code> <code>DTypeLike</code> <p>Floating dtype (e.g. np.float64).</p> <code>float64</code> <code>bc</code> <code>str</code> <p>Boundary condition; either \"neumann\" or \"absorbing\".</p> <code>'neumann'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unknown boundary condition is provided.</p> <p>Returns:</p> Type Description <code>csr_matrix</code> <p>Sparse CSR matrix representing the Laplacian operator.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def build_laplacian_tridiag(\n    n: int,\n    dx: float,\n    coeff: float,\n    dtype: DTypeLike = np.float64,\n    bc: str = \"neumann\",\n) -&gt; csr_matrix:\n    \"\"\"Build a Laplacian tridiagonal matrix for a given boundary condition.\n\n    The resulting operator corresponds to `coeff * \u0394_h`, where `\u0394_h` is the\n    standard second-order central-difference Laplacian in 1D. No time-step\n    scaling is applied here; `coeff` is interpreted as the physical diffusion\n    coefficient `D` or a generic spatial scaling.\n\n    Args:\n        n: Number of grid points.\n        dx: Grid spacing.\n        coeff: Physical diffusion coefficient D (units length^2 / time).\n        dtype: Floating dtype (e.g. np.float64).\n        bc: Boundary condition; either \"neumann\" or \"absorbing\".\n\n    Raises:\n        ValueError: If an unknown boundary condition is provided.\n\n    Returns:\n        Sparse CSR matrix representing the Laplacian operator.\n    \"\"\"\n    dtype_obj = np.dtype(dtype)\n    factor = coeff / dx**2\n\n    main_diag = -2.0 * np.ones(n, dtype=dtype_obj)\n    off_diag = np.ones(n - 1, dtype=dtype_obj)\n\n    if bc == \"neumann\":\n        main_diag[0] = -1.0\n        main_diag[-1] = -1.0\n    elif bc == \"absorbing\":\n        main_diag[0] = -2.0\n        main_diag[-1] = -2.0\n    else:\n        msg = _UNKNOWN_BC_ERROR.format(bc=bc)\n        raise ValueError(msg)\n\n    laplacian = diags(\n        [off_diag.tolist(), main_diag.tolist(), off_diag.tolist()],\n        [-1, 0, 1],\n        shape=(n, n),\n        dtype=dtype_obj,\n    )\n\n    scaled = laplacian * factor\n    return scaled.tocsr()\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.build_predictor_corrector","title":"<code>build_predictor_corrector(base_matrix)</code>","text":"<p>Build predictor-corrector matrices with dense/sparse autodispatch.</p> <p>Parameters:</p> Name Type Description Default <code>base_matrix</code> <code>DenseOperator | csr_matrix</code> <p>Base linear operator A.</p> required <p>Returns:</p> Type Description <code>tuple[Operator, Operator, Operator]</code> <p>Tuple of (predictor, L, R) operators for predictor-corrector scheme.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def build_predictor_corrector(\n    base_matrix: DenseOperator | csr_matrix,\n) -&gt; tuple[Operator, Operator, Operator]:\n    \"\"\"\n    Build predictor-corrector matrices with dense/sparse autodispatch.\n\n    Args:\n        base_matrix: Base linear operator A.\n\n    Returns:\n        Tuple of (predictor, L, R) operators for predictor-corrector scheme.\n    \"\"\"\n    n = base_matrix.shape[0]\n    if issparse(base_matrix) and n &gt;= _DISPATCH_THRESHOLD:\n        return _build_predictor_corrector_sparse(base_matrix)\n\n    if issparse(base_matrix):\n        dense_base = np.asarray(base_matrix.toarray())\n    else:\n        dense_base = np.asarray(base_matrix)\n\n    return _build_predictor_corrector_dense(cast(\"DenseOperator\", dense_base))\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.build_trapezoidal_operators","title":"<code>build_trapezoidal_operators(base_op, dt_scale)</code>","text":"<p>Build trapezoidal operators for a time-scaled linear operator.</p> <p>Parameters:</p> Name Type Description Default <code>base_op</code> <code>Operator</code> <p>Base linear operator A.</p> required <code>dt_scale</code> <code>float</code> <p>Time-step scaling factor (dt * scale).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If dt_scale is not finite.</p> <p>Returns:</p> Type Description <code>tuple[Operator, Operator]</code> <p>Tuple of (L, R) operators for trapezoidal scheme.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def build_trapezoidal_operators(\n    base_op: Operator,\n    dt_scale: float,\n) -&gt; tuple[Operator, Operator]:\n    \"\"\"Build trapezoidal operators for a time-scaled linear operator.\n\n    Args:\n        base_op: Base linear operator A.\n        dt_scale: Time-step scaling factor (dt * scale).\n\n    Raises:\n        ValueError: If dt_scale is not finite.\n\n    Returns:\n        Tuple of (L, R) operators for trapezoidal scheme.\n    \"\"\"\n    if not np.isfinite(dt_scale):\n        raise ValueError(_OPERATOR_SCALE_ERROR.format(scale=dt_scale))\n\n    n = base_op.shape[0]\n    half = 0.5 * dt_scale\n\n    if issparse(base_op):\n        base_csr = base_op.tocsr()\n        identity_mat = identity(n, format=\"csr\", dtype=base_csr.dtype)\n        left_csr = (identity_mat - (half * base_csr)).tocsr()\n        right_csr = (identity_mat + (half * base_csr)).tocsr()\n        return cast(\"csr_matrix\", left_csr), cast(\"csr_matrix\", right_csr)\n\n    base_arr = np.asarray(base_op)\n    identity_arr = np.eye(n, dtype=base_arr.dtype)\n    left_arr = identity_arr - (half * base_arr)\n    right_arr = identity_arr + (half * base_arr)\n    return cast(\"DenseOperator\", left_arr), cast(\"DenseOperator\", right_arr)\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.clear_implicit_solver_cache","title":"<code>clear_implicit_solver_cache()</code>","text":"<p>Clear the internal implicit solver cache.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def clear_implicit_solver_cache() -&gt; None:\n    \"\"\"Clear the internal implicit solver cache.\"\"\"\n    _IMPLICIT_SOLVER_CACHE.clear()\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.encode_groups","title":"<code>encode_groups(group_ids, n_groups, *, prefer_sparse=None, dtype=np.float64)</code>","text":"<p>Encode group IDs into a one-hot group membership matrix.</p> <p>Parameters:</p> Name Type Description Default <code>group_ids</code> <code>NDArray[integer]</code> <p>1D array of integer group IDs for each item.</p> required <code>n_groups</code> <code>int</code> <p>Total number of groups.</p> required <code>prefer_sparse</code> <code>bool | None</code> <p>If True, always return a sparse matrix; if False, always return a dense array; if None, autodispatch based on n_groups.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Data type for the output matrix.</p> <code>float64</code> <p>Returns:</p> Type Description <code>csr_matrix | DenseOperator</code> <p>A (n_groups, n_items) one-hot encoded group membership matrix.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def encode_groups(\n    group_ids: NDArray[np.integer],\n    n_groups: int,\n    *,\n    prefer_sparse: bool | None = None,\n    dtype: DTypeLike = np.float64,\n) -&gt; csr_matrix | DenseOperator:\n    \"\"\"\n    Encode group IDs into a one-hot group membership matrix.\n\n    Args:\n        group_ids: 1D array of integer group IDs for each item.\n        n_groups: Total number of groups.\n        prefer_sparse: If True, always return a sparse matrix; if False, always\n            return a dense array; if None, autodispatch based on n_groups.\n        dtype: Data type for the output matrix.\n\n    Returns:\n        A (n_groups, n_items) one-hot encoded group membership matrix.\n    \"\"\"\n    group_ids_arr = np.asarray(group_ids, dtype=np.int64)\n\n    if prefer_sparse is True:\n        return _encode_sparse_groups(group_ids_arr, n_groups, dtype=dtype)\n    if prefer_sparse is False:\n        return _encode_dense_groups(group_ids_arr, n_groups, dtype=dtype)\n\n    if n_groups &gt;= _DISPATCH_THRESHOLD:\n        return _encode_sparse_groups(group_ids_arr, n_groups, dtype=dtype)\n    return _encode_dense_groups(group_ids_arr, n_groups, dtype=dtype)\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.grouped_count_ids","title":"<code>grouped_count_ids(group_ids, n_groups)</code>","text":"<p>Perform grouped count using group IDs.</p> <p>Parameters:</p> Name Type Description Default <code>group_ids</code> <code>NDArray[integer]</code> <p>1D array of integer group IDs.</p> required <code>n_groups</code> <code>int</code> <p>Total number of groups.</p> required <p>Returns:</p> Type Description <code>NDArray[floating]</code> <p>A 1D array of length n_groups where each element contains the count of</p> <code>NDArray[floating]</code> <p>occurrences of the corresponding group ID.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def grouped_count_ids(\n    group_ids: NDArray[np.integer],\n    n_groups: int,\n) -&gt; NDArray[np.floating]:\n    \"\"\"\n    Perform grouped count using group IDs.\n\n    Args:\n        group_ids: 1D array of integer group IDs.\n        n_groups: Total number of groups.\n\n    Returns:\n        A 1D array of length n_groups where each element contains the count of\n        occurrences of the corresponding group ID.\n    \"\"\"\n    group_ids_arr = np.asarray(group_ids, dtype=np.int64)\n    counts = np.bincount(group_ids_arr, minlength=n_groups)\n    return counts.astype(float)\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.grouped_sum_ids","title":"<code>grouped_sum_ids(values, group_ids, n_groups)</code>","text":"<p>Perform grouped sum over 1D values array using group IDs.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[floating]</code> <p>1D array of values.</p> required <code>group_ids</code> <code>NDArray[integer]</code> <p>1D array of integer group IDs.</p> required <code>n_groups</code> <code>int</code> <p>Total number of groups.</p> required <p>Returns:</p> Type Description <code>NDArray[floating]</code> <p>A 1D array of length n_groups where each element contains the sum of values</p> <code>NDArray[floating]</code> <p>for the corresponding group ID.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def grouped_sum_ids(\n    values: NDArray[np.floating],\n    group_ids: NDArray[np.integer],\n    n_groups: int,\n) -&gt; NDArray[np.floating]:\n    \"\"\"\n    Perform grouped sum over 1D values array using group IDs.\n\n    Args:\n        values: 1D array of values.\n        group_ids: 1D array of integer group IDs.\n        n_groups: Total number of groups.\n\n    Returns:\n        A 1D array of length n_groups where each element contains the sum of values\n        for the corresponding group ID.\n    \"\"\"\n    values_arr = np.asarray(values)\n    group_ids_arr = np.asarray(group_ids, dtype=np.int64)\n    sums = np.bincount(group_ids_arr, weights=values_arr, minlength=n_groups)\n    return sums.astype(float)\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.grouped_sum_ids_2d","title":"<code>grouped_sum_ids_2d(values, group_ids, n_groups)</code>","text":"<p>Perform grouped sum over 2D values array using group IDs.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray[floating]</code> <p>2D (N, K) array where N is num of items and K is num of features.</p> required <code>group_ids</code> <code>NDArray[integer]</code> <p>1D array of integer group IDs of length N.</p> required <code>n_groups</code> <code>int</code> <p>Total number of groups.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If values is not 2D or if group_ids length does not match the number of items in values.</p> <p>Returns:</p> Type Description <code>NDArray[floating]</code> <p>A 2D array of shape (n_groups, K) where each row contains the sum of values</p> <code>NDArray[floating]</code> <p>for the corresponding group ID.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def grouped_sum_ids_2d(\n    values: NDArray[np.floating],\n    group_ids: NDArray[np.integer],\n    n_groups: int,\n) -&gt; NDArray[np.floating]:\n    \"\"\"\n    Perform grouped sum over 2D values array using group IDs.\n\n    Args:\n        values: 2D (N, K) array where N is num of items and K is num of features.\n        group_ids: 1D array of integer group IDs of length N.\n        n_groups: Total number of groups.\n\n    Raises:\n        ValueError: If values is not 2D or if group_ids length does not match\n            the number of items in values.\n\n    Returns:\n        A 2D array of shape (n_groups, K) where each row contains the sum of values\n        for the corresponding group ID.\n    \"\"\"\n    values_arr = np.asarray(values)\n    group_ids_arr = np.asarray(group_ids, dtype=np.int64)\n\n    if values_arr.ndim != 2:\n        raise ValueError(_VALUES_2D_ERROR)\n\n    n_items, n_features = values_arr.shape\n    if group_ids_arr.shape[0] != n_items:\n        raise ValueError(_GROUP_IDS_LENGTH_ERROR)\n\n    out = np.zeros((n_groups, n_features), dtype=values_arr.dtype)\n    for feature_idx in range(n_features):\n        out[:, feature_idx] = np.bincount(\n            group_ids_arr,\n            weights=values_arr[:, feature_idx],\n            minlength=n_groups,\n        )\n    return out\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.implicit_solve","title":"<code>implicit_solve(left_op, right_op, x)</code>","text":"<p>Perform an implicit solve with dense/sparse dispatch and caching.</p> <p>Parameters:</p> Name Type Description Default <code>left_op</code> <code>Operator</code> <p>Left operator L in the equation L @ y = R @ x.</p> required <code>right_op</code> <code>Operator</code> <p>Right operator R in the equation L @ y = R @ x.</p> required <code>x</code> <code>NDArray[floating]</code> <p>1D or 2D array representing the input vector(s).</p> required <p>Returns:</p> Type Description <code>NDArray[floating]</code> <p>A 1D or 2D array containing the solution vector(s) y.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def implicit_solve(\n    left_op: Operator,\n    right_op: Operator,\n    x: NDArray[np.floating],\n) -&gt; NDArray[np.floating]:\n    \"\"\"\n    Perform an implicit solve with dense/sparse dispatch and caching.\n\n    Args:\n        left_op: Left operator L in the equation L @ y = R @ x.\n        right_op: Right operator R in the equation L @ y = R @ x.\n        x: 1D or 2D array representing the input vector(s).\n\n    Returns:\n        A 1D or 2D array containing the solution vector(s) y.\n    \"\"\"\n    x_arr = np.asarray(x)\n    _validate_solve_dimensions(left_op, right_op, cast(\"NDArray[np.floating]\", x_arr))\n\n    key = (id(left_op), id(right_op))\n    meta = _operator_meta(left_op, right_op)\n\n    cached = _IMPLICIT_SOLVER_CACHE.get(key)\n    if cached is not None:\n        cached_meta, solver = cached\n        if cached_meta != meta:\n            solver = _build_implicit_solver(left_op, right_op)\n            _IMPLICIT_SOLVER_CACHE[key] = (meta, solver)\n        return solver(cast(\"NDArray[np.floating]\", x_arr))\n\n    solver = _build_implicit_solver(left_op, right_op)\n    _IMPLICIT_SOLVER_CACHE[key] = (meta, solver)\n    return solver(cast(\"NDArray[np.floating]\", x_arr))\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.kron_prod","title":"<code>kron_prod(a, b)</code>","text":"<p>Compute the Kronecker product of two operators.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Operator</code> <p>First operator.</p> required <code>b</code> <code>Operator</code> <p>Second operator.</p> required <p>Returns:</p> Type Description <code>Operator</code> <p>The Kronecker product operator.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def kron_prod(a: Operator, b: Operator) -&gt; Operator:\n    \"\"\"\n    Compute the Kronecker product of two operators.\n\n    Args:\n        a: First operator.\n        b: Second operator.\n\n    Returns:\n        The Kronecker product operator.\n    \"\"\"\n    if issparse(a) or issparse(b):\n        a_csr = a if issparse(a) else csr_matrix(np.asarray(a))\n        b_csr = b if issparse(b) else csr_matrix(np.asarray(b))\n        return kron(\n            a_csr,\n            b_csr,\n            format=\"csr\",\n        )\n    return cast(\"DenseOperator\", np.kron(np.asarray(a), np.asarray(b)))\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.kron_sum","title":"<code>kron_sum(ops)</code>","text":"<p>Compute a Kronecker sum of square operators.</p> <p>Parameters:</p> Name Type Description Default <code>ops</code> <code>list[Operator]</code> <p>List of 2D square operators.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If ops is empty or if operators are not square or have incompatible shapes.</p> <p>Returns:</p> Type Description <code>Operator</code> <p>The Kronecker sum operator.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def kron_sum(ops: list[Operator]) -&gt; Operator:\n    \"\"\"\n    Compute a Kronecker sum of square operators.\n\n    Args:\n        ops: List of 2D square operators.\n\n    Raises:\n        ValueError: If ops is empty or if operators are not square or\n            have incompatible shapes.\n\n    Returns:\n        The Kronecker sum operator.\n    \"\"\"\n    if not ops:\n        raise ValueError(_KRON_EMPTY_ERROR)\n\n    shapes = [\n        tuple(np.asarray(op).shape) if not issparse(op) else op.shape for op in ops\n    ]\n\n    if any(s[0] != s[1] for s in shapes):\n        raise ValueError(_KRON_INCOMPATIBLE_ERROR.format(shapes=shapes))\n\n    any_sparse = any(issparse(op) for op in ops)\n    sizes = [s[0] for s in shapes]\n    dtype_obj = np.result_type(*[\n        (op.dtype if issparse(op) else np.asarray(op).dtype) for op in ops\n    ])\n\n    def _eye(n: int) -&gt; Operator:\n        if any_sparse:\n            return identity(n, format=\"csr\", dtype=dtype_obj)\n        return cast(\"DenseOperator\", np.eye(n, dtype=dtype_obj))\n\n    total: Operator | None = None\n    n_ops = len(ops)\n\n    for i, op_i in enumerate(ops):\n        term: Operator = op_i\n        for j in range(i - 1, -1, -1):\n            term = kron_prod(_eye(sizes[j]), term)\n        for j in range(i + 1, n_ops):\n            term = kron_prod(term, _eye(sizes[j]))\n        total = term if total is None else cast(\"Operator\", total + term)\n\n    if total is None:\n        raise ValueError(_KRON_EMPTY_ERROR)\n    return total\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.make_constant_base_builder","title":"<code>make_constant_base_builder(operator)</code>","text":"<p>Convenience: wrap a constant operator as a BaseOperatorBuilder.</p> <p>Parameters:</p> Name Type Description Default <code>operator</code> <code>Operator</code> <p>Constant operator to wrap.</p> required <p>Returns:</p> Type Description <code>BaseOperatorBuilder</code> <p>A BaseOperatorBuilder that always returns the given operator.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def make_constant_base_builder(operator: Operator) -&gt; BaseOperatorBuilder:\n    \"\"\"\n    Convenience: wrap a constant operator as a BaseOperatorBuilder.\n\n    Args:\n        operator: Constant operator to wrap.\n\n    Returns:\n        A BaseOperatorBuilder that always returns the given operator.\n    \"\"\"\n    operator_0 = _ensure_operator_type(operator)\n\n    def _builder(ctx: StageOperatorContext) -&gt; Operator:  # noqa: ARG001\n        return operator_0\n\n    return _builder\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.make_stage_operator_factory","title":"<code>make_stage_operator_factory(base_builder, *, scheme='implicit-euler')</code>","text":"<p>Create a stage operator factory supporting time/state dependent base ops.</p> <p>Parameters:</p> Name Type Description Default <code>base_builder</code> <code>BaseOperatorBuilder</code> <p>Function that builds a base operator given stage context.</p> required <code>scheme</code> <code>str</code> <p>Implicit scheme; either \"implicit-euler\" or \"trapezoidal\".</p> <code>'implicit-euler'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unknown scheme is provided.</p> <p>Returns:</p> Type Description <code>StageOperatorFactory</code> <p>A StageOperatorFactory that builds (L, R) operators for the given scheme.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def make_stage_operator_factory(\n    base_builder: BaseOperatorBuilder,\n    *,\n    scheme: str = \"implicit-euler\",\n) -&gt; StageOperatorFactory:\n    \"\"\"\n    Create a stage operator factory supporting time/state dependent base ops.\n\n    Args:\n        base_builder: Function that builds a base operator given stage context.\n        scheme: Implicit scheme; either \"implicit-euler\" or \"trapezoidal\".\n\n    Raises:\n        ValueError: If an unknown scheme is provided.\n\n    Returns:\n        A StageOperatorFactory that builds (L, R) operators for the given scheme.\n    \"\"\"\n    scheme_norm = str(scheme).strip().lower()\n\n    if scheme_norm == \"implicit-euler\":\n\n        def _factory(\n            dt: float, scale: float, ctx: StageOperatorContext\n        ) -&gt; tuple[Operator, Operator]:\n            operator = _ensure_operator_type(base_builder(ctx))\n            return build_implicit_euler_operators(operator, float(dt) * float(scale))\n\n        return _factory\n\n    if scheme_norm == \"trapezoidal\":\n\n        def _factory(\n            dt: float, scale: float, ctx: StageOperatorContext\n        ) -&gt; tuple[Operator, Operator]:\n            operator = _ensure_operator_type(base_builder(ctx))\n            return build_trapezoidal_operators(operator, float(dt) * float(scale))\n\n        return _factory\n\n    raise ValueError(_UNKNOWN_SCHEME_ERROR.format(scheme=scheme))\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.matrix_grouped_count","title":"<code>matrix_grouped_count(group_matrix)</code>","text":"<p>Perform grouped count using a group matrix.</p> <p>Parameters:</p> Name Type Description Default <code>group_matrix</code> <code>csr_matrix | DenseOperator</code> <p>2D group matrix (csr_matrix or dense ndarray).</p> required <p>Returns:</p> Type Description <code>NDArray[floating]</code> <p>A 1D array containing the counts for each group.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def matrix_grouped_count(\n    group_matrix: csr_matrix | DenseOperator,\n) -&gt; NDArray[np.floating]:\n    \"\"\"\n    Perform grouped count using a group matrix.\n\n    Args:\n        group_matrix: 2D group matrix (csr_matrix or dense ndarray).\n\n    Returns:\n        A 1D array containing the counts for each group.\n    \"\"\"\n    n_groups = group_matrix.shape[0]\n    if issparse(group_matrix) and n_groups &gt;= _DISPATCH_THRESHOLD:\n        return _matrix_grouped_count_sparse(group_matrix)\n    if issparse(group_matrix):\n        dense_matrix = group_matrix.toarray()\n    else:\n        dense_matrix = np.asarray(group_matrix)\n    return _matrix_grouped_count_dense(cast(\"DenseOperator\", dense_matrix))\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.matrix_grouped_sum","title":"<code>matrix_grouped_sum(group_matrix, values)</code>","text":"<p>Perform grouped sum using a group matrix.</p> <p>Parameters:</p> Name Type Description Default <code>group_matrix</code> <code>csr_matrix | DenseOperator</code> <p>2D group matrix (csr_matrix or dense ndarray).</p> required <code>values</code> <code>NDArray[floating]</code> <p>1D array of values to be summed.</p> required <p>Returns:</p> Type Description <code>NDArray[floating]</code> <p>A 1D array containing the grouped sums.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def matrix_grouped_sum(\n    group_matrix: csr_matrix | DenseOperator,\n    values: NDArray[np.floating],\n) -&gt; NDArray[np.floating]:\n    \"\"\"\n    Perform grouped sum using a group matrix.\n\n    Args:\n        group_matrix: 2D group matrix (csr_matrix or dense ndarray).\n        values: 1D array of values to be summed.\n\n    Returns:\n        A 1D array containing the grouped sums.\n    \"\"\"\n    n_groups = group_matrix.shape[0]\n    if issparse(group_matrix) and n_groups &gt;= _DISPATCH_THRESHOLD:\n        return _matrix_grouped_sum_sparse(group_matrix, values)\n    if issparse(group_matrix):\n        dense_matrix = np.asarray(group_matrix.toarray())\n    else:\n        dense_matrix = np.asarray(group_matrix)\n    return _matrix_grouped_sum_dense(cast(\"DenseOperator\", dense_matrix), values)\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.matrix_masked_sum","title":"<code>matrix_masked_sum(mask_matrix, data)</code>","text":"<p>Perform masked sum using a mask matrix and data array.</p> <p>Parameters:</p> Name Type Description Default <code>mask_matrix</code> <code>csr_matrix | DenseOperator</code> <p>2D mask matrix (csr_matrix or dense ndarray).</p> required <code>data</code> <code>NDArray[floating]</code> <p>1D or 2D data array to be masked and summed.</p> required <p>Returns:</p> Type Description <code>NDArray[floating]</code> <p>A 1D or 2D array containing the masked sums.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def matrix_masked_sum(\n    mask_matrix: csr_matrix | DenseOperator,\n    data: NDArray[np.floating],\n) -&gt; NDArray[np.floating]:\n    \"\"\"\n    Perform masked sum using a mask matrix and data array.\n\n    Args:\n        mask_matrix: 2D mask matrix (csr_matrix or dense ndarray).\n        data: 1D or 2D data array to be masked and summed.\n\n    Returns:\n        A 1D or 2D array containing the masked sums.\n    \"\"\"\n    n_masks = mask_matrix.shape[0]\n    if issparse(mask_matrix) and n_masks &gt;= _DISPATCH_THRESHOLD:\n        return _matrix_masked_sum_sparse(mask_matrix, data)\n    if issparse(mask_matrix):\n        dense_matrix = np.asarray(mask_matrix.toarray())\n    else:\n        dense_matrix = np.asarray(mask_matrix)\n    return _matrix_masked_sum_dense(dense_matrix, data)\n</code></pre>"},{"location":"api-reference/matrix_ops/#op_engine.matrix_ops.smooth","title":"<code>smooth(x, alpha=0.02, out=None)</code>","text":"<p>Apply simple smoothing along the last axis.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>NDArray[floating]</code> <p>Input array to smooth.</p> required <code>alpha</code> <code>float</code> <p>Smoothing factor between 0 and 1.</p> <code>0.02</code> <code>out</code> <code>NDArray[floating] | None</code> <p>Optional output array to store the result.</p> <code>None</code> <p>Returns:</p> Type Description <code>NDArray[floating]</code> <p>Smoothed array with the same shape as x.</p> Source code in <code>src/op_engine/matrix_ops.py</code> <pre><code>def smooth(\n    x: NDArray[np.floating],\n    alpha: float = 0.02,\n    out: NDArray[np.floating] | None = None,\n) -&gt; NDArray[np.floating]:\n    \"\"\"\n    Apply simple smoothing along the last axis.\n\n    Args:\n        x: Input array to smooth.\n        alpha: Smoothing factor between 0 and 1.\n        out: Optional output array to store the result.\n\n    Returns:\n        Smoothed array with the same shape as x.\n    \"\"\"\n    x_arr = np.asarray(x)\n    smoothed = (1.0 - alpha) * x_arr + alpha * x_arr.mean(axis=-1, keepdims=True)\n    if out is not None:\n        np.copyto(out, smoothed)\n        return out\n    return cast(\"NDArray[np.floating]\", smoothed)\n</code></pre>"},{"location":"api-reference/model_core/","title":"Model Core","text":""},{"location":"api-reference/model_core/#op_engine.model_core","title":"<code>model_core</code>","text":"<p>Core class for managing the numerical state of a model.</p> <p>This module provides a lightweight state container and time-grid manager for time-evolving models. It is designed to support:</p> <ul> <li>Non-uniform time grids via per-step dt accessors.</li> <li>Multi-axis state tensors (e.g., state x age x space x traits).</li> <li>Optional full history storage for post-analysis.</li> <li>A minimal backend hook to ease future NumPy-&gt;(JAX/CuPy) integration.</li> </ul> <p>The core intentionally does not build RHS functions or construct operators; it only manages state, time, and shape/axis metadata in a solver-friendly manner.</p>"},{"location":"api-reference/model_core/#op_engine.model_core.ArrayBackend","title":"<code>ArrayBackend</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Minimal array backend interface for ModelCore numerical storage.</p>"},{"location":"api-reference/model_core/#op_engine.model_core.ArrayBackend.asarray","title":"<code>asarray(x, dtype=None)</code>","text":"<p>Convert input to an array of the backend type.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def asarray(\n    self,\n    x: object,\n    dtype: object | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Convert input to an array of the backend type.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ArrayBackend.zeros","title":"<code>zeros(shape, dtype=None)</code>","text":"<p>Return a new array of given shape filled with zeros.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def zeros(\n    self,\n    shape: tuple[int, ...],\n    dtype: object | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Return a new array of given shape filled with zeros.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore","title":"<code>ModelCore(n_states, n_subgroups, time_grid, *, options=None)</code>","text":"<p>Core state and time manager for time-evolving models.</p> <p>Initialize ModelCore.</p> <p>Parameters:</p> Name Type Description Default <code>n_states</code> <code>int</code> <p>Number of state variables.</p> required <code>n_subgroups</code> <code>int</code> <p>Number of subgroups (e.g., age groups).</p> required <code>time_grid</code> <code>ndarray</code> <p>1D array of times, shape (n_timesteps,).</p> required <code>options</code> <code>ModelCoreOptions | None</code> <p>Optional ModelCoreOptions for additional configuration.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if time_grid is invalid or any shapes mismatch.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def __init__(\n    self,\n    n_states: int,\n    n_subgroups: int,\n    time_grid: np.ndarray,\n    *,\n    options: ModelCoreOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize ModelCore.\n\n    Args:\n        n_states: Number of state variables.\n        n_subgroups: Number of subgroups (e.g., age groups).\n        time_grid: 1D array of times, shape (n_timesteps,).\n        options: Optional ModelCoreOptions for additional configuration.\n\n    Raises:\n        ValueError: if time_grid is invalid or any shapes mismatch.\n    \"\"\"\n    opts = options or ModelCoreOptions()\n\n    # Forward-compat hook; stored for later wiring. For now ModelCore remains\n    # NumPy-first; higher layers can decide how to allocate/convert.\n    self.xp = opts.xp\n\n    self.dtype = np.dtype(opts.dtype)\n\n    self.time_grid = np.asarray(time_grid, dtype=self.dtype)\n    if self.time_grid.ndim != 1:\n        raise ValueError(_TIMEGRID_1D_ERROR)\n\n    self.n_timesteps = int(self.time_grid.size)\n    if self.n_timesteps &lt; 1:\n        raise ValueError(_TIMEGRID_MIN_POINTS_ERROR)\n\n    if self.n_timesteps &gt; 1:\n        dt_arr = np.diff(self.time_grid)\n        if np.any(dt_arr &lt;= 0):\n            raise ValueError(_TIMEGRID_MONOTONE_ERROR)\n        self.dt_grid = np.asarray(dt_arr, dtype=self.dtype)\n        self.dt = float(self.dt_grid.mean())\n    else:\n        self.dt_grid = np.asarray([], dtype=self.dtype)\n        self.dt = 0.0\n\n    self.n_states = int(n_states)\n    self.n_subgroups = int(n_subgroups)\n    self._other_axes = tuple(int(x) for x in opts.other_axes)\n\n    self.state_shape = (self.n_states, self.n_subgroups, *self._other_axes)\n    self.store_history = bool(opts.store_history)\n\n    if opts.axis_names is None:\n        base = [\"state\", \"subgroup\"]\n        extra = [f\"axis{i}\" for i in range(2, len(self.state_shape))]\n        self.axis_names = tuple(base + extra)\n    else:\n        if len(opts.axis_names) != len(self.state_shape):\n            raise ValueError(\n                _AXIS_NAMES_LEN_ERROR.format(\n                    actual=len(opts.axis_names),\n                    expected=len(self.state_shape),\n                )\n            )\n        self.axis_names = tuple(opts.axis_names)\n\n    self.axis_coords: dict[str, np.ndarray] = {}\n    if opts.axis_coords is not None:\n        self.axis_coords = {\n            str(k): np.asarray(v, dtype=self.dtype)\n            for k, v in opts.axis_coords.items()\n        }\n\n    self.current_step = 0\n\n    # Per-timestep working state (contiguous).\n    self.current_state = np.zeros(self.state_shape, dtype=self.dtype)\n\n    # Optional full history: (n_timesteps, *state_shape)\n    self.state_array: FloatArray | None\n    if self.store_history:\n        self.state_array = cast(\n            \"FloatArray\",\n            np.zeros((self.n_timesteps, *self.state_shape), dtype=self.dtype),\n        )\n    else:\n        self.state_array = None\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.current_time","title":"<code>current_time</code>  <code>property</code>","text":"<p>Current simulation time t = time_grid[current_step].</p> <p>Returns:</p> Type Description <code>float</code> <p>Current time as a float.</p>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.state_ndim","title":"<code>state_ndim</code>  <code>property</code>","text":"<p>Number of state tensor dimensions (rank).</p> <p>Returns:</p> Type Description <code>int</code> <p>State tensor rank as an integer.</p>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.advance_timestep","title":"<code>advance_timestep(next_state)</code>","text":"<p>Alias for apply_next_state, for solver-friendly naming.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def advance_timestep(self, next_state: np.ndarray) -&gt; None:\n    \"\"\"Alias for apply_next_state, for solver-friendly naming.\"\"\"\n    self.apply_next_state(next_state)\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.apply_deltas","title":"<code>apply_deltas(deltas)</code>","text":"<p>Apply state deltas, advancing the timestep.</p> <p>Supports alternate solver implementations (e.g., splitting updates, additive increments) without forcing allocation of y_next.</p> <p>Parameters:</p> Name Type Description Default <code>deltas</code> <code>ndarray</code> <p>State deltas to apply, shape state_shape.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if deltas has incorrect shape.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def apply_deltas(self, deltas: np.ndarray) -&gt; None:\n    \"\"\"\n    Apply state deltas, advancing the timestep.\n\n    Supports alternate solver implementations (e.g., splitting updates,\n    additive increments) without forcing allocation of y_next.\n\n    Args:\n        deltas: State deltas to apply, shape state_shape.\n\n    Raises:\n        ValueError: if deltas has incorrect shape.\n    \"\"\"\n    deltas_arr = np.asarray(deltas, dtype=self.dtype)\n    if deltas_arr.shape != self.state_shape:\n        raise ValueError(\n            _DELTAS_SHAPE_ERROR.format(\n                actual=deltas_arr.shape, expected=self.state_shape\n            )\n        )\n\n    self._check_can_advance()\n\n    self.current_state += deltas_arr\n\n    self.current_step += 1\n    if self.store_history and self.state_array is not None:\n        self.state_array[self.current_step] = self.current_state\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.apply_next_state","title":"<code>apply_next_state(next_state)</code>","text":"<p>Set the next state directly, advancing the timestep.</p> <p>Parameters:</p> Name Type Description Default <code>next_state</code> <code>ndarray</code> <p>State at the next timestep, shape state_shape.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if next_state has incorrect shape.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def apply_next_state(self, next_state: np.ndarray) -&gt; None:\n    \"\"\"\n    Set the next state directly, advancing the timestep.\n\n    Args:\n        next_state: State at the next timestep, shape state_shape.\n\n    Raises:\n        ValueError: if next_state has incorrect shape.\n    \"\"\"\n    next_state_arr = np.asarray(next_state, dtype=self.dtype)\n    if next_state_arr.shape != self.state_shape:\n        raise ValueError(\n            _NEXT_STATE_SHAPE_ERROR.format(\n                actual=next_state_arr.shape, expected=self.state_shape\n            )\n        )\n\n    self._check_can_advance()\n\n    np.copyto(self.current_state, next_state_arr)\n\n    self.current_step += 1\n    if self.store_history and self.state_array is not None:\n        self.state_array[self.current_step] = self.current_state\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.axis_index","title":"<code>axis_index(axis)</code>","text":"<p>Resolve an axis name or integer into an axis index.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>str | int</code> <p>Axis name or index.</p> required <p>Raises:</p> Type Description <code>IndexError</code> <p>if axis index is out of bounds.</p> <code>ValueError</code> <p>if axis name is unknown.</p> <p>Returns:</p> Type Description <code>int</code> <p>Axis index as an integer.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def axis_index(self, axis: str | int) -&gt; int:\n    \"\"\"\n    Resolve an axis name or integer into an axis index.\n\n    Args:\n        axis: Axis name or index.\n\n    Raises:\n        IndexError: if axis index is out of bounds.\n        ValueError: if axis name is unknown.\n\n    Returns:\n        Axis index as an integer.\n    \"\"\"\n    if isinstance(axis, int):\n        if not (0 &lt;= axis &lt; self.state_ndim):\n            raise IndexError(_AXIS_INDEX_OOB_ERROR.format(axis=axis))\n        return axis\n\n    try:\n        return self.axis_names.index(axis)\n    except ValueError as exc:\n        raise ValueError(_AXIS_UNKNOWN_ERROR.format(axis=axis)) from exc\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.get_axis_coords","title":"<code>get_axis_coords(axis)</code>","text":"<p>Return coordinate array for a given axis, or None if not set.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>str | int</code> <p>Axis name or index.</p> required <p>Returns:</p> Type Description <code>ndarray | None</code> <p>Coordinate array for the axis, or None if not set.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def get_axis_coords(self, axis: str | int) -&gt; np.ndarray | None:\n    \"\"\"\n    Return coordinate array for a given axis, or None if not set.\n\n    Args:\n        axis: Axis name or index.\n\n    Returns:\n        Coordinate array for the axis, or None if not set.\n    \"\"\"\n    idx = self.axis_index(axis)\n    name = self.axis_names[idx]\n    return self.axis_coords.get(name)\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.get_current_state","title":"<code>get_current_state()</code>","text":"<p>Retrun the current state.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Current state, shape state_shape.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def get_current_state(self) -&gt; np.ndarray:\n    \"\"\"\n    Retrun the current state.\n\n    Returns:\n        Current state, shape state_shape.\n    \"\"\"\n    return self.current_state\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.get_dt","title":"<code>get_dt(step_idx)</code>","text":"<p>Return dt for the step [t_step_idx, t_step_idx+1].</p> <p>Parameters:</p> Name Type Description Default <code>step_idx</code> <code>int</code> <p>Timestep index in [0, n_timesteps - 1].</p> required <p>Raises:</p> Type Description <code>IndexError</code> <p>if step_idx is out of bounds.</p> <p>Returns:</p> Type Description <code>float</code> <p>dt as a float.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def get_dt(self, step_idx: int) -&gt; float:\n    \"\"\"\n    Return dt for the step [t_step_idx, t_step_idx+1].\n\n    Args:\n        step_idx: Timestep index in [0, n_timesteps - 1].\n\n    Raises:\n        IndexError: if step_idx is out of bounds.\n\n    Returns:\n        dt as a float.\n    \"\"\"\n    if self.n_timesteps &lt;= 1:\n        return 0.0\n    if not (0 &lt;= step_idx &lt; self.n_timesteps - 1):\n        raise IndexError(_DT_INDEX_OOB_ERROR.format(idx=step_idx))\n    return float(self.dt_grid[step_idx])\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.get_state_at","title":"<code>get_state_at(step)</code>","text":"<p>Return the state at a given timestep from history.</p> <p>Parameters:</p> Name Type Description Default <code>step</code> <code>int</code> <p>Timestep index in [0, n_timesteps).</p> required <p>Returns:</p> Type Description <code>FloatArray</code> <p>State at the given timestep, shape state_shape.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if history is not stored.</p> <code>IndexError</code> <p>if step is out of bounds.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def get_state_at(self, step: int) -&gt; FloatArray:\n    \"\"\"\n    Return the state at a given timestep from history.\n\n    Args:\n        step: Timestep index in [0, n_timesteps).\n\n    Returns:\n        State at the given timestep, shape state_shape.\n\n    Raises:\n        RuntimeError: if history is not stored.\n        IndexError: if step is out of bounds.\n    \"\"\"\n    if not self.store_history or self.state_array is None:\n        raise RuntimeError(_HISTORY_NOT_STORED_ERROR)\n\n    if not (0 &lt;= step &lt; self.n_timesteps):\n        raise IndexError(_STEP_OOB_ERROR)\n\n    # NumPy typing stubs often type ndarray.__getitem__ as Any under mypy,\n    # which triggers --strict [no-any-return] without an explicit cast.\n    return cast(\"FloatArray\", self.state_array[step])\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.get_time_at","title":"<code>get_time_at(step_idx)</code>","text":"<p>Return time at a given step index.</p> <p>Parameters:</p> Name Type Description Default <code>step_idx</code> <code>int</code> <p>Timestep index in [0, n_timesteps).</p> required <p>Raises:</p> Type Description <code>IndexError</code> <p>if step_idx is out of bounds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Time as a float.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def get_time_at(self, step_idx: int) -&gt; float:\n    \"\"\"\n    Return time at a given step index.\n\n    Args:\n        step_idx: Timestep index in [0, n_timesteps).\n\n    Raises:\n        IndexError: if step_idx is out of bounds.\n\n    Returns:\n        Time as a float.\n    \"\"\"\n    if not (0 &lt;= step_idx &lt; self.n_timesteps):\n        raise IndexError(_TIME_INDEX_OOB_ERROR.format(idx=step_idx))\n    return float(self.time_grid[step_idx])\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.reshape_for_axis_solve","title":"<code>reshape_for_axis_solve(x, axis)</code>","text":"<p>Reshape a state-like tensor into 2D for an axis-local operator solve.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>State-like tensor of shape state_shape.</p> required <code>axis</code> <code>str | int</code> <p>Axis name or index along which to reshape.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, tuple[int, ...], int]</code> <p>(x2d, original_shape, axis_index)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if x does not have shape state_shape.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def reshape_for_axis_solve(\n    self,\n    x: np.ndarray,\n    axis: str | int,\n) -&gt; tuple[np.ndarray, tuple[int, ...], int]:\n    \"\"\"Reshape a state-like tensor into 2D for an axis-local operator solve.\n\n    Args:\n        x: State-like tensor of shape state_shape.\n        axis: Axis name or index along which to reshape.\n\n    Returns:\n        (x2d, original_shape, axis_index)\n\n    Raises:\n        ValueError: if x does not have shape state_shape.\n    \"\"\"\n    x_arr = np.asarray(x, dtype=self.dtype)\n    if x_arr.shape != self.state_shape:\n        raise ValueError(\n            _NEXT_STATE_SHAPE_ERROR.format(\n                actual=x_arr.shape, expected=self.state_shape\n            )\n        )\n\n    original_shape = x_arr.shape\n    axis_idx = self.axis_index(axis)\n    axis_len = int(original_shape[axis_idx])\n\n    moved = np.moveaxis(x_arr, axis_idx, 0)\n    x2d = moved.reshape(axis_len, -1)\n    return x2d, original_shape, axis_idx\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.set_initial_state","title":"<code>set_initial_state(initial_state)</code>","text":"<p>Set the initial state at time_grid[0].</p> <p>Parameters:</p> Name Type Description Default <code>initial_state</code> <code>ndarray</code> <p>Initial state, shape state_shape.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if initial_state has incorrect shape.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def set_initial_state(self, initial_state: np.ndarray) -&gt; None:\n    \"\"\"\n    Set the initial state at time_grid[0].\n\n    Args:\n        initial_state: Initial state, shape state_shape.\n\n    Raises:\n        ValueError: if initial_state has incorrect shape.\n    \"\"\"\n    initial_state_arr = np.asarray(initial_state, dtype=self.dtype)\n    if initial_state_arr.shape != self.state_shape:\n        raise ValueError(\n            _INITIAL_STATE_SHAPE_ERROR.format(\n                actual=initial_state_arr.shape,\n                expected=self.state_shape,\n            )\n        )\n\n    np.copyto(self.current_state, initial_state_arr)\n\n    if self.store_history and self.state_array is not None:\n        self.state_array[0] = self.current_state\n\n    self.current_step = 0\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.unreshape_from_axis_solve","title":"<code>unreshape_from_axis_solve(x2d, original_shape, axis)</code>","text":"<p>Inverse of reshape_for_axis_solve.</p> <p>Parameters:</p> Name Type Description Default <code>x2d</code> <code>ndarray</code> <p>2D array of shape (axis_len, batch).</p> required <code>original_shape</code> <code>tuple[int, ...]</code> <p>Original full shape before reshape.</p> required <code>axis</code> <code>str | int</code> <p>Axis name or index along which the reshape was done.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Reconstructed array of shape original_shape.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def unreshape_from_axis_solve(\n    self,\n    x2d: np.ndarray,\n    original_shape: tuple[int, ...],\n    axis: str | int,\n) -&gt; np.ndarray:\n    \"\"\"\n    Inverse of reshape_for_axis_solve.\n\n    Args:\n        x2d: 2D array of shape (axis_len, batch).\n        original_shape: Original full shape before reshape.\n        axis: Axis name or index along which the reshape was done.\n\n    Returns:\n        Reconstructed array of shape original_shape.\n    \"\"\"\n    axis_idx = self.axis_index(axis)\n    axis_len = int(original_shape[axis_idx])\n\n    # Rebuild shape with axis leading, then move it back.\n    trailing = tuple(d for i, d in enumerate(original_shape) if i != axis_idx)\n    arr = np.asarray(x2d, dtype=self.dtype).reshape((axis_len, *trailing))\n    return np.moveaxis(arr, 0, axis_idx)\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCore.validate_state_shape","title":"<code>validate_state_shape(arr, *, msg=None)</code>","text":"<p>Validate that arr has state_shape.</p> <p>This is intentionally small and solver-friendly; higher layers can reuse it to avoid duplicating shape checks for intermediate/stage states.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Array to validate.</p> required <code>msg</code> <code>str | None</code> <p>Optional custom error message prefix.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if arr does not have shape state_shape.</p> Source code in <code>src/op_engine/model_core.py</code> <pre><code>def validate_state_shape(self, arr: np.ndarray, *, msg: str | None = None) -&gt; None:\n    \"\"\"\n    Validate that arr has state_shape.\n\n    This is intentionally small and solver-friendly; higher layers can reuse it\n    to avoid duplicating shape checks for intermediate/stage states.\n\n    Args:\n        arr: Array to validate.\n        msg: Optional custom error message prefix.\n\n    Raises:\n        ValueError: if arr does not have shape state_shape.\n    \"\"\"\n    arr_shape = np.asarray(arr).shape\n    if arr_shape != self.state_shape:\n        raise ValueError(\n            (msg or _NEXT_STATE_SHAPE_ERROR).format(\n                actual=arr_shape, expected=self.state_shape\n            )\n        )\n</code></pre>"},{"location":"api-reference/model_core/#op_engine.model_core.ModelCoreOptions","title":"<code>ModelCoreOptions(other_axes=(), axis_names=None, axis_coords=None, store_history=True, dtype=np.float64, xp=np)</code>  <code>dataclass</code>","text":"<p>Optional configuration for ModelCore.</p> <p>This object groups non-essential constructor parameters to keep the ModelCore initializer compact and stable while allowing future extensions without breaking the public API.</p> <p>Attributes:</p> Name Type Description <code>other_axes</code> <code>tuple[int, ...]</code> <p>Additional axis sizes appended after the default (state, subgroup) axes. Example: (n_space,) or (n_space, n_trait).</p> <code>axis_names</code> <code>tuple[str, ...] | None</code> <p>Optional names for each axis in the state tensor. Length must equal the total state rank.</p> <code>axis_coords</code> <code>Mapping[str, ndarray] | None</code> <p>Optional coordinate arrays keyed by axis name. This is metadata only and enables non-uniform grids and FV/FDM operator builders.</p> <code>store_history</code> <code>bool</code> <p>Whether to store the full time history.</p> <code>dtype</code> <code>DTypeLike</code> <p>Floating-point dtype for internal arrays.</p> <code>xp</code> <code>object</code> <p>Array backend module (default NumPy). This is a forward- compatibility hook for GPU backends.</p>"},{"location":"guides/getting-started/","title":"Getting Started","text":"<p>A brief tutorial on how to get started with <code>OP Engine</code>.</p> <pre><code>import math\nfoo = 2 * math.pi\n</code></pre> <p>And then</p> <pre><code>&gt;&gt;&gt; foo\n6.283185307179586\n</code></pre>"}]}